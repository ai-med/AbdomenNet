{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import nibabel  # for loading and saving nifty files\n",
    "import torch\n",
    "from math import ceil, floor\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import Pad\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nibabel.affines import from_matvec, to_matvec, apply_affine\n",
    "\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nibabel.orientations import axcodes2ornt, ornt_transform, inv_ornt_aff\n",
    "import ants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing steps for KORA\n",
    "\n",
    "1. rescale to positive intensity values (needed for N4 correction), so far just add 10, save original values in .pkl file\n",
    "2. bias field correction (N4) compute on in-phase scan (external script)\n",
    "3. apply in-phase bias field to opp scans\n",
    "4. rescale intensities back to original values (after bias phase correction, the intensities are close to 0 → second N4 won’t work if we don’t rescale the intensities)\n",
    "\n",
    "Now for in and opp scans:\n",
    "5. change orientation to RAS \n",
    "6. resampling of lower scan to the resolution of upper scan\n",
    "7. merging of upper and lower scan\n",
    "8. rescale to positive intensity values (needed for N4 correction)\n",
    "9. compute bias field correction on merged in-phase scans (external script)\n",
    "10. apply bias field correction to merged opp scans\n",
    "\n",
    "missing: intensity standardization across all KORA scans, cropping of scans to a common FOV & size\n",
    "\n",
    "Segmentations:\n",
    "11. merging of segmentation files and changing of labels to 0:7\n",
    "12. optional: resampling to 2,2,3mm (only needed when we want to create a KORANAKOUKB dataset)\n",
    "\n",
    "intensity standardization across datasets? (KORA, NAKO, UKB)\n",
    "\n",
    "\n",
    "Some problems: so far running this on rtx locally, getting corrupted files when running directly on nas. why?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. rescale to positive intensity values of iso_in scans (needed for N4 correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save 2 lists of original filenames and original (min,max values) - to use for rescaling the n4 corrected scans back\n",
    "# to their original intensity range\n",
    "\n",
    "original_values_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_intensities(img_files, data_dir,sequence):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    values = []\n",
    "    original_filenames = [[],[]]\n",
    "    original_values = [[],[]]\n",
    "    _, pat_id = os.path.split(data_dir)\n",
    "    print('Pat ID ', pat_id)\n",
    "    if sequence == 'in':\n",
    "        print('create entry in dict for ', pat_id)\n",
    "        original_values_dict[pat_id] = {}\n",
    "    original_values_dict[pat_id][sequence] = {}\n",
    "    original_values_dict[pat_id][sequence]['filenames'] = []\n",
    "    original_values_dict[pat_id][sequence]['min_max_values'] = []\n",
    "\n",
    "    # load files\n",
    "    for file in img_files:\n",
    "        if \"nii.gz\" in file:\n",
    "            img = nibabel.load(os.path.join(data_dir, file))\n",
    "            print('filename: ', file)\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            filename, file_extension = os.path.splitext(filename)\n",
    "            original_values_dict[pat_id][sequence]['filenames'].append(filename)\n",
    "\n",
    "            images.append(img)\n",
    "            img_data = np.asanyarray(img.dataobj)\n",
    "            min_value = np.min(img_data)\n",
    "            max_value = np.max(img_data)\n",
    "            print('dtype ', img_data.dtype)\n",
    "            print('img.get_data_dtype() ', img.get_data_dtype())\n",
    "            print('header dtpye ', img.header['datatype'])\n",
    "            print('header bitpix ', img.header['bitpix'])\n",
    "            #print(img.header)\n",
    "            print('min value: ', min_value )\n",
    "            print('max value: ', max_value)\n",
    "            \n",
    "            if min_value < 0:\n",
    "                print('Negative values detected!!')\n",
    "            else:\n",
    "                new_img_data = img_data + 10\n",
    "            min_value = np.min(new_img_data)\n",
    "            max_value = np.max(new_img_data)\n",
    "            print('new min value: ', min_value )\n",
    "            print('new max value: ', max_value)\n",
    "            print('new image dtype ', new_img_data.dtype)\n",
    "            original_values_dict[pat_id][sequence]['min_max_values'].append([min_value,max_value])\n",
    "\n",
    "            new_img_nii = nibabel.Nifti1Image(new_img_data, img.affine.copy(), img.header.copy())\n",
    "            new_file_path = os.path.join(data_dir,filename + '_rescaled.nii.gz')\n",
    "            nibabel.save(new_img_nii, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/'\n",
    "\n",
    "listFolders =  os.listdir(data_dir)\n",
    "for folder in listFolders:\n",
    "    print(folder)\n",
    "    path = data_dir + folder\n",
    "    listFiles = os.listdir(path)\n",
    "    sequence = 'in'\n",
    "    in_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and 'corrected' not in f and not'resampled' in f and not 'rescaled' in f ]\n",
    "    print(in_files)\n",
    "\n",
    "    rescale_intensities(in_files, path,sequence)\n",
    "    \n",
    "    sequence = 'opp'\n",
    "    opp_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and 'corrected' not in f and not'resampled' in f and not 'rescaled' in f ]\n",
    "    print(opp_files)\n",
    "\n",
    "    rescale_intensities(opp_files, path,sequence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t1_vibe_dixon_cor_caipi6_bh_288_iso_in_6.nii.gz', 't1_vibe_dixon_cor_caipi6_bh_288_iso_in_7.nii.gz']\n",
      "Pat ID  KORA2452879\n",
      "create entry in dict for  KORA2452879\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_in_6.nii.gz\n",
      "dtype  float32\n",
      "img.get_data_dtype()  float32\n",
      "header dtpye  16\n",
      "header bitpix  32\n",
      "min value:  0.0\n",
      "max value:  895.0\n",
      "new min value:  10.0\n",
      "new max value:  905.0\n",
      "new image dtype  float32\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_in_7.nii.gz\n",
      "dtype  float32\n",
      "img.get_data_dtype()  float32\n",
      "header dtpye  16\n",
      "header bitpix  32\n",
      "min value:  0.0\n",
      "max value:  548.0\n",
      "new min value:  10.0\n",
      "new max value:  558.0\n",
      "new image dtype  float32\n",
      "['t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_9.nii.gz', 't1_vibe_dixon_cor_caipi6_bh_288_iso_opp_8.nii.gz']\n",
      "Pat ID  KORA2452879\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_9.nii.gz\n",
      "dtype  float32\n",
      "img.get_data_dtype()  float32\n",
      "header dtpye  16\n",
      "header bitpix  32\n",
      "min value:  0.0\n",
      "max value:  524.0\n",
      "new min value:  10.0\n",
      "new max value:  534.0\n",
      "new image dtype  float32\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_8.nii.gz\n",
      "dtype  float32\n",
      "img.get_data_dtype()  float32\n",
      "header dtpye  16\n",
      "header bitpix  32\n",
      "min value:  0.0\n",
      "max value:  879.0\n",
      "new min value:  10.0\n",
      "new max value:  889.0\n",
      "new image dtype  float32\n"
     ]
    }
   ],
   "source": [
    "# if sth went wrong can run it here again for single patient\n",
    "path = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/KORA2452879'\n",
    "listFiles = os.listdir(path)\n",
    "sequence = 'in'\n",
    "in_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and 'corrected' not in f and not'resampled' in f and not 'rescaled' in f ]\n",
    "print(in_files)\n",
    "\n",
    "rescale_intensities(in_files, path,sequence)\n",
    "sequence = 'opp'\n",
    "opp_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and 'corrected' not in f and not'resampled' in f and not 'rescaled' in f ]\n",
    "print(opp_files)\n",
    "\n",
    "rescale_intensities(opp_files, path,sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "print(original_values_dict)\n",
    "file = open('original_values_dict.pkl', 'wb')\n",
    "pickle.dump(original_values_dict, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Run N4 bias field correction on rescaled in scans. (script n4.sh under /home/anne/whole_body_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. load bias field masks of in scans and apply them to opp scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bias_fields(img_files, bias_fields, data_dir,sequence):\n",
    "    images = []\n",
    "    bias_f = []\n",
    "    filenames = []\n",
    "    # load files\n",
    "    for file in img_files:\n",
    "        if \"nii.gz\" in file:\n",
    "            img = nibabel.load(os.path.join(data_dir, file))\n",
    "            print('filename: ', file)\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            filename, file_extension = os.path.splitext(filename)\n",
    "            \n",
    "            images.append(img)\n",
    "            filenames.append(filename)\n",
    "    for file in bias_fields:\n",
    "        if \"nii.gz\" in file:\n",
    "            img = nibabel.load(os.path.join(data_dir, file))\n",
    "            print('filename: ', file)            \n",
    "            bias_f.append(img)\n",
    "\n",
    "    images_sorted, filenames_sorted = zip(*sorted(zip(images,filenames), key=lambda im: im[0].header['qoffset_z'], reverse=True))\n",
    "    bias_f = sorted(bias_f, key=lambda im: im.header['qoffset_z'], reverse=True)\n",
    "    \n",
    "    im_0 = images_sorted[0]\n",
    "    im_1 = images_sorted[1]\n",
    "    \n",
    "    bias_0 = bias_f[0]\n",
    "    bias_1 = bias_f[1]\n",
    "    \n",
    "    # manually apply bias field to image:\n",
    "    im_0_data = np.asanyarray(im_0.dataobj)\n",
    "    im_1_data = np.asanyarray(im_1.dataobj)\n",
    "    print('min ', np.min(im_0_data))\n",
    "    print('max ', np.max(im_0_data))\n",
    "    bias_0_data = bias_0.get_fdata()\n",
    "    bias_1_data = bias_1.get_fdata()\n",
    "    print('min ', np.min(bias_0_data))\n",
    "    print('max ', np.max(bias_0_data))\n",
    "    \n",
    "    corrected_0 = im_0_data / bias_0_data\n",
    "    corrected_1 = im_1_data / bias_1_data\n",
    "    print('min ', np.min(corrected_0))\n",
    "    print('max ', np.max(corrected_0))\n",
    "\n",
    "    new_img_nii = nibabel.Nifti1Image(corrected_0, im_0.affine, im_0.header)\n",
    "    new_file_path = os.path.join(data_dir,filenames_sorted[0] + '_applied_in_bias_corrected.nii.gz')\n",
    "    nibabel.save(new_img_nii, new_file_path)\n",
    "    \n",
    "    new_img_nii = nibabel.Nifti1Image(corrected_1, im_1.affine, im_1.header)\n",
    "    new_file_path = os.path.join(data_dir,filenames_sorted[1] + '_applied_in_bias_corrected.nii.gz')\n",
    "    nibabel.save(new_img_nii, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/'\n",
    "\n",
    "listFolders =  os.listdir(data_dir)\n",
    "for folder in listFolders:\n",
    "    print(folder)\n",
    "    path = data_dir + folder\n",
    "    listFiles = os.listdir(path)\n",
    "    # sequence for bias fields is 'in'\n",
    "    sequence = 'in'\n",
    "    bias_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and 'corrected' not in f and not'resampled' in f and 'rescaled' in f and 'bias' in f ]\n",
    "    print(bias_files)\n",
    "    # want to apply in bias fields on opp scans, so load opp scans here:\n",
    "    sequence = 'opp'\n",
    "    opp_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and 'corrected' not in f and not'resampled' in f and 'rescaled' in f and not 'bias' in f ]\n",
    "    print(opp_files)\n",
    "    apply_bias_fields(opp_files, bias_files, path,sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t1_vibe_dixon_cor_caipi6_bh_288_iso_in_7_rescaled_bias_field.nii.gz', 't1_vibe_dixon_cor_caipi6_bh_288_iso_in_6_rescaled_bias_field.nii.gz']\n",
      "['t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_9_rescaled.nii.gz', 't1_vibe_dixon_cor_caipi6_bh_288_iso_opp_8_rescaled.nii.gz']\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_9_rescaled.nii.gz\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_8_rescaled.nii.gz\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_in_7_rescaled_bias_field.nii.gz\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_in_6_rescaled_bias_field.nii.gz\n",
      "min  10.0\n",
      "max  889.0\n",
      "min  72.12023162841797\n",
      "max  525.4364624023438\n",
      "min  0.019736438320949973\n",
      "max  5.259675841356089\n"
     ]
    }
   ],
   "source": [
    "# if sth went wrong can run it here again for single patient\n",
    "path = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/KORA2452879'\n",
    "listFiles = os.listdir(path)\n",
    "sequence = 'in'\n",
    "bias_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and 'corrected' not in f and not'resampled' in f and 'rescaled' in f and 'bias' in f ]\n",
    "print(bias_files)\n",
    "    \n",
    "sequence = 'opp'\n",
    "opp_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and 'corrected' not in f and not'resampled' in f and 'rescaled' in f and not 'bias' in f ]\n",
    "print(opp_files)\n",
    "apply_bias_fields(opp_files, bias_files, path,sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Rescale images back to their original intensity range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_intensities(img_files, data_dir,sequence):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    _,pat_id = os.path.split(data_dir)\n",
    "    # load files\n",
    "    for file in img_files:\n",
    "        if \"nii.gz\" in file:\n",
    "            img = nibabel.load(os.path.join(data_dir, file))\n",
    "            print('filename: ', file)\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            filename, file_extension = os.path.splitext(filename)\n",
    "            filenames.append(filename)\n",
    "            images.append(img)\n",
    "            img_data = img.get_fdata()\n",
    "            \n",
    "    images_sorted, filenames_sorted = zip(*sorted(zip(images,filenames), key=lambda im: im[1], reverse=True))\n",
    "    original_values_dict[pat_id][sequence]['filenames'], original_values_dict[pat_id][sequence]['min_max_values'] = zip(*sorted(zip(original_values_dict[pat_id][sequence]['filenames'],original_values_dict[pat_id][sequence]['min_max_values']), key=lambda im: im[0], reverse=True))\n",
    "\n",
    "    for i, img in enumerate(images_sorted):\n",
    "        orig_f = original_values_dict[pat_id][sequence]['filenames'][i]\n",
    "        orig_v = original_values_dict[pat_id][sequence]['min_max_values'][i]\n",
    "        name = filenames_sorted[i]\n",
    "        \n",
    "        print('name: ', name)\n",
    "        print('orig name: ', orig_f)\n",
    "        print('orig values ', orig_v)\n",
    "        \n",
    "        img_data = img.get_fdata()\n",
    "        min_value = np.min(img_data)\n",
    "        max_value = np.max(img_data)\n",
    "        print('img min: ', min_value)\n",
    "        print('img max: ', max_value)\n",
    "        \n",
    "        img_data = (img_data - min_value) * (orig_v[1] - orig_v[0])/(max_value - min_value) + orig_v[0]\n",
    "        \n",
    "        print('new min: ', np.min(img_data))\n",
    "        print('new max: ', np.max(img_data))\n",
    "        \n",
    "        new_img_nii = nibabel.Nifti1Image(img_data, img.affine, img.header)\n",
    "        new_file_path = os.path.join(data_dir,name + '_rescaled_original.nii.gz')\n",
    "        nibabel.save(new_img_nii, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/'\n",
    "\n",
    "listFolders =  os.listdir(data_dir)\n",
    "for folder in listFolders:\n",
    "    print(folder)\n",
    "    path = data_dir + folder\n",
    "    listFiles = os.listdir(path)\n",
    "    sequence = 'in'\n",
    "    in_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'rescaled_corrected' in f and 'bias' not in f ]\n",
    "    print(in_files)\n",
    "\n",
    "    rescale_intensities(in_files, path,sequence)\n",
    "    \n",
    "    sequence = 'opp'\n",
    "    opp_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'rescaled_applied_in_bias_corrected' in f ]\n",
    "    print(opp_files)\n",
    "\n",
    "    rescale_intensities(opp_files, path,sequence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_8_rescaled_applied_in_bias_corrected.nii.gz', 't1_vibe_dixon_cor_caipi6_bh_288_iso_opp_9_rescaled_applied_in_bias_corrected.nii.gz']\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_8_rescaled_applied_in_bias_corrected.nii.gz\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_9_rescaled_applied_in_bias_corrected.nii.gz\n",
      "name:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_9_rescaled_applied_in_bias_corrected\n",
      "orig name:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_9\n",
      "orig values  [10.0, 534.0]\n",
      "img min:  0.014345293864607811\n",
      "img max:  2.8343071937561035\n",
      "new min:  10.0\n",
      "new max:  534.0\n",
      "name:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_8_rescaled_applied_in_bias_corrected\n",
      "orig name:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_8\n",
      "orig values  [10.0, 889.0]\n",
      "img min:  0.019736438989639282\n",
      "img max:  5.259675979614258\n",
      "new min:  10.0\n",
      "new max:  889.0\n"
     ]
    }
   ],
   "source": [
    "# if sth went wrong can run it here again for single patient\n",
    "path = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/KORA2452879'\n",
    "listFiles = os.listdir(path)\n",
    "\n",
    "    \n",
    "sequence = 'opp'\n",
    "opp_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'rescaled_applied_in_bias_corrected.nii.gz' in f ]\n",
    "print(opp_files)\n",
    "rescale_intensities(opp_files, path,sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5+6: Reorient to RAS and resample lower scan to upper scan resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nibabel.processing import resample_to_output, resample_from_to\n",
    "def reorient_and_resample_images(img_files, data_dir, sequence, target_voxel_dim):\n",
    "    images = []\n",
    "    filenames = []\n",
    "    # load files\n",
    "    for file in img_files:\n",
    "        if \"nii.gz\" in file:\n",
    "            img = nibabel.load(os.path.join(data_dir, file))\n",
    "            print('filename: ', file)\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            filename, file_extension = os.path.splitext(filename)\n",
    "            filenames.append(filename)\n",
    "            \n",
    "            print('min value: ', np.min(img.get_fdata()))\n",
    "            print('max value: ', np.max(img.get_fdata()))\n",
    "            #print(img_h.get_data_shape())\n",
    "            print('original orientation: ', nibabel.orientations.aff2axcodes(img.header.get_best_affine()))\n",
    "\n",
    "            # convert to RAS so that this code works:\n",
    "            img = do_nibabel_transform_to_ras(img)\n",
    "            print('min value: ', np.min(img.get_fdata()))\n",
    "            print('max value: ', np.max(img.get_fdata()))\n",
    "            images.append(img)\n",
    "            \n",
    "            img_h = img.header\n",
    "\n",
    "            steps = img_h['pixdim'][1:4]\n",
    "            \n",
    "\n",
    "    images_sorted, filenames_sorted = zip(*sorted(zip(images,filenames), key=lambda im: im[0].header['qoffset_z'], reverse=True))\n",
    "    #print(sorted(zip(images,filenames), key=lambda im: im[0].header['qoffset_z'], reverse=True))\n",
    "    img_0 = images_sorted[0]\n",
    "    img_1 = images_sorted[1]\n",
    "    \n",
    "    print('im 0 affine: ', img_0.header.get_best_affine())\n",
    "    print('im 1 affine: ', img_1.header.get_best_affine())\n",
    "\n",
    "    target_affine = img_0.header.get_best_affine()\n",
    "    target_affine[2,3] = img_1.header.get_best_affine()[2,3]\n",
    "    img_1 = resample_from_to(img_1, [img_1.shape, target_affine])\n",
    "    print('min value: ', np.min(img_1.get_fdata()))\n",
    "    print('max value: ', np.max(img_1.get_fdata()))\n",
    "    new_file_path = os.path.join(data_dir,filenames_sorted[1]+'_resampled.nii.gz')\n",
    "\n",
    "    nibabel.save(img_1, new_file_path)\n",
    "    \n",
    "    new_file_path = os.path.join(data_dir,filenames_sorted[0]+'_resampled.nii.gz')\n",
    "\n",
    "    nibabel.save(img_0, new_file_path)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_nibabel_transform_to_ras(img):\n",
    "    ###### use nibabel transform\n",
    "    affine = img.get_affine()\n",
    "    orig_ornt = nibabel.io_orientation(affine)\n",
    "    #print('orig image orientation: ', orig_ornt)\n",
    "    #print('transform to RAS')\n",
    "    targ_ornt = axcodes2ornt('RAS')\n",
    "    #print('target orientation: ', targ_ornt)\n",
    "    transform = ornt_transform(orig_ornt, targ_ornt)\n",
    "    #fat_tmp = fat.get_data()\n",
    "    img = img.as_reoriented(transform)\n",
    "    #print('img shape after nibabel transform: ', img.get_data().shape)\n",
    "\n",
    "    #########################\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/'\n",
    "\n",
    "listFolders =  os.listdir(data_dir)\n",
    "for folder in listFolders:\n",
    "    print(folder)\n",
    "    path = data_dir + folder\n",
    "    listFiles = os.listdir(path)\n",
    "    sequence = 'opp'\n",
    "    # with previous bias field correction\n",
    "    opp_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and '_applied_in_bias_corrected_rescaled_original' in f and not 'resampled' in f ]\n",
    "    # without previous bias field correction\n",
    "    #opp_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and not '_applied_in_bias_corrected' in f and not 'resampled' in f ]\n",
    "\n",
    "    print(opp_files)\n",
    "    print('first reorient and resample')\n",
    "    reorient_and_resample_images(opp_files, path, sequence, [2,2,3])\n",
    "    \n",
    "    sequence = 'in'\n",
    "    in_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and '_rescaled_corrected_rescaled_original' in f and not 'resampled' in f ]\n",
    "    # without previous bias field correction\n",
    "    #in_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and not '_rescaled_corrected' in f and not 'resampled' in f ]\n",
    "\n",
    "    print(in_files)\n",
    "    print('first reorient and resample')\n",
    "    reorient_and_resample_images(in_files, path, sequence, [2,2,3])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_9_rescaled_applied_in_bias_corrected_rescaled_original.nii.gz', 't1_vibe_dixon_cor_caipi6_bh_288_iso_opp_8_rescaled_applied_in_bias_corrected_rescaled_original.nii.gz']\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_9_rescaled_applied_in_bias_corrected_rescaled_original.nii.gz\n",
      "min value:  10.0\n",
      "max value:  534.0\n",
      "original orientation:  ('L', 'I', 'P')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anne/anaconda3/envs/mesh_env/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning:\n",
      "\n",
      "get_affine method is deprecated.\n",
      "Please use the ``img.affine`` property instead.\n",
      "\n",
      "* deprecated from version: 2.1\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 4.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min value:  10.0\n",
      "max value:  534.0\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_8_rescaled_applied_in_bias_corrected_rescaled_original.nii.gz\n",
      "min value:  10.0\n",
      "max value:  889.0\n",
      "original orientation:  ('L', 'I', 'P')\n",
      "min value:  10.0\n",
      "max value:  889.0\n",
      "im 0 affine:  [[   1.70138884    0.            0.         -243.27729797]\n",
      " [   0.            1.69999695    0.         -151.14399719]\n",
      " [   0.            0.            1.70138884 -468.50531006]\n",
      " [   0.            0.            0.            1.        ]]\n",
      "im 1 affine:  [[   1.66666663    0.            0.         -238.31202698]\n",
      " [   0.            1.69999695    0.         -151.14399719]\n",
      " [   0.            0.            1.66666663 -693.54003906]\n",
      " [   0.            0.            0.            1.        ]]\n",
      "min value:  -9.355963706970215\n",
      "max value:  540.888916015625\n"
     ]
    }
   ],
   "source": [
    "# if sth went wrong can run it here again for single patient\n",
    "path = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/KORA2452879'\n",
    "listFiles = os.listdir(path)\n",
    "\n",
    "    \n",
    "sequence = 'opp'\n",
    "opp_files = [f for f in listFiles if sequence in f and 'COMP' not in f and 'comb' not in f and '_applied_in_bias_corrected_rescaled_original' in f and not 'resampled' in f ]\n",
    "print(opp_files)\n",
    "reorient_and_resample_images(opp_files, path,sequence, [2,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Merging of upper and lower scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_images(opp_files, data_dir, sequence):\n",
    "    \n",
    "    images = []\n",
    "    filenames = []\n",
    "    # load files\n",
    "    for file in opp_files:\n",
    "        if \"nii.gz\" in file:\n",
    "            img = nibabel.load(os.path.join(data_dir, file))\n",
    "            print('filename: ', file)\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            filename, file_extension = os.path.splitext(filename)\n",
    "            images.append(img)\n",
    "            \n",
    "            img_h = img.header\n",
    "            print('x: ', img_h['qoffset_x'])\n",
    "            print('y: ', img_h['qoffset_y'])\n",
    "            print('z: ', img_h['qoffset_z'])\n",
    "            \n",
    "            print('min value: ', np.min(img.get_fdata()))\n",
    "            print('max value: ', np.max(img.get_fdata()))\n",
    "            filenames.append(filename)\n",
    "            \n",
    "\n",
    "    \n",
    "   \n",
    "    images_sorted, filenames_sorted = zip(*sorted(zip(images,filenames), key=lambda im: im[0].header['qoffset_z'], reverse=True))\n",
    " \n",
    "    #take the upper 2 scans\n",
    "    im_0 = images_sorted[0]\n",
    "    im_1 = images_sorted[1]\n",
    "\n",
    "    im_0_dim_v = im_0.shape[2]\n",
    "    im_1_dim_v = im_1.shape[2]\n",
    "\n",
    "    #print(im_0_dim_v)\n",
    "\n",
    "    # calculate overlap region:\n",
    "    im_0_end = im_0.header['qoffset_z']\n",
    "    im_1_end = im_1.header['qoffset_z']\n",
    "    print('im_0_end, im_1,end: ', im_0_end, im_1_end)\n",
    "\n",
    "    spacing = im_0.header['pixdim'][3]\n",
    "    print('pixel spacing: ', spacing)\n",
    "\n",
    "    im_0_dim_w = im_0_dim_v * spacing\n",
    "    im_1_dim_w = im_1_dim_v * spacing\n",
    "\n",
    "    im_1_start = im_1_end + im_1_dim_w\n",
    "    im_0_start = im_0_end + im_0_dim_w\n",
    "    print('im_0_start, im_1,start: ', im_1_start, im_0_start)\n",
    "\n",
    "    overlap = abs(im_0_end - im_1_start)\n",
    "    print('overlap: ', overlap)\n",
    "\n",
    "    overlap_v = int(round(overlap/spacing))\n",
    "    print('overlap_v: ', overlap_v)\n",
    "\n",
    "    new_im_dim = round((abs(im_1_end - im_0_end) + abs(im_0_end - im_0_start))/spacing)\n",
    "    print('new im dim: ', new_im_dim)\n",
    "    \n",
    "    new_img = np.empty([im_0.shape[0], im_0.shape[1], int(new_im_dim)])\n",
    "    print('new img shape: ', new_img.shape)\n",
    "    im_0_data = im_0.get_data()\n",
    "    im_1_data = im_1.get_data()\n",
    "\n",
    "\n",
    "    # bottom ( origin is bottom left)    \n",
    "    new_img[:,:,0:(im_1_dim_v-overlap_v)] = im_1_data[:,:,0:(im_1_dim_v-overlap_v)]    \n",
    "    # top:\n",
    "    new_img[:,:, im_1_dim_v:] = im_0_data[:,:,overlap_v:]\n",
    "    \n",
    "    # overlap region:\n",
    "    a = 1/overlap_v\n",
    "    print('overlap_v ', overlap_v)\n",
    "    print('a ', a)\n",
    "    sig = sigmoid(overlap_v)\n",
    "    for l in range(0,overlap_v):\n",
    "        #new_img[:,:,(im_1_dim_v-overlap_v+l)] = (1-a*l) * im_1_data[:,:,(im_1_dim_v-overlap_v)+l] + (a*l) * im_0_data[:,:,l]\n",
    "        new_img[:,:,(im_1_dim_v-overlap_v+l)] = (1-sig[l]) * im_1_data[:,:,(im_1_dim_v-overlap_v)+l] + (sig[l]) * im_0_data[:,:,l]\n",
    "\n",
    "    empty_header = nibabel.Nifti1Header()\n",
    "    new_img_nii = nibabel.Nifti1Image(new_img, im_1.affine, empty_header)\n",
    "    new_img_nii.header['pixdim'] = im_1.header['pixdim']\n",
    "\n",
    "    #print('new header: ', new_img_nii.header)\n",
    "    new_file_path = os.path.join(data_dir,'t1_vibe_dixon_cor_caipi6_bh_288_iso_%s_corrected_comb_sigm.nii.gz'%sequence)\n",
    "\n",
    "    nibabel.save(new_img_nii, new_file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def sigmoid(v_overlap):\n",
    "    x = np.linspace(0, v_overlap, v_overlap)\n",
    "    k = 0.5\n",
    "    x0 = v_overlap//2\n",
    "    z = 1/(1 + np.exp(-k*(x-x0))) \n",
    "    #print(z)\n",
    "\n",
    "    #plt.plot(x, z) \n",
    "    #plt.xlabel(\"x\") \n",
    "    #plt.ylabel(\"Sigmoid(X)\") \n",
    "\n",
    "    #plt.show() \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/'\n",
    "\n",
    "listFolders =  os.listdir(data_dir)\n",
    "for folder in listFolders:\n",
    "    print(folder)\n",
    "    path = data_dir + folder\n",
    "    listFiles = os.listdir(path)\n",
    "    sequence = 'opp'\n",
    "    opp_files = [f for f in listFiles if sequence in f and  '_applied_in_bias_corrected_rescaled_original_resampled' in f ]\n",
    "    # without previous bias field correction\n",
    "    #opp_files = [f for f in listFiles if sequence in f and not 'comb' in f and not'_applied_in_bias_corrected' in f and 'resampled' in f]\n",
    "\n",
    "    print(opp_files)\n",
    "    merge_images(opp_files, path,sequence)\n",
    "    \n",
    "    sequence = 'in'\n",
    "    \n",
    "    in_files = [f for f in listFiles if sequence in f and  '_rescaled_original_resampled' in f and 'opp' not in f ]\n",
    "    # without previous bias field correction\n",
    "    #in_files = [f for f in listFiles if sequence in f and not 'comb' in f and not '_rescaled_corrected' in f and 'resampled' in f]\n",
    "\n",
    "    print(in_files)\n",
    "    merge_images(in_files, path,sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_8_rescaled_applied_in_bias_corrected_rescaled_original_resampled.nii.gz', 't1_vibe_dixon_cor_caipi6_bh_288_iso_opp_9_rescaled_applied_in_bias_corrected_rescaled_original_resampled.nii.gz']\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_8_rescaled_applied_in_bias_corrected_rescaled_original_resampled.nii.gz\n",
      "x:  -243.2773\n",
      "y:  -151.144\n",
      "z:  -468.5053\n",
      "min value:  10.0\n",
      "max value:  889.0\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_9_rescaled_applied_in_bias_corrected_rescaled_original_resampled.nii.gz\n",
      "x:  -243.2773\n",
      "y:  -151.144\n",
      "z:  -693.54004\n",
      "min value:  -9.355963706970215\n",
      "max value:  540.888916015625\n",
      "im_0_end, im_1,end:  -468.5053 -693.54004\n",
      "pixel spacing:  1.7013888\n",
      "im_0_start, im_1,start:  -203.54005432128906 21.494674682617188\n",
      "overlap:  264.9652557373047\n",
      "overlap_v:  156\n",
      "new im dim:  420.0\n",
      "new img shape:  (288, 160, 420)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anne/anaconda3/envs/mesh_env/lib/python3.6/site-packages/ipykernel_launcher.py:63: DeprecationWarning:\n",
      "\n",
      "get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "\n",
      "/home/anne/anaconda3/envs/mesh_env/lib/python3.6/site-packages/ipykernel_launcher.py:64: DeprecationWarning:\n",
      "\n",
      "get_data() is deprecated in favor of get_fdata(), which has a more predictable return type. To obtain get_data() behavior going forward, use numpy.asanyarray(img.dataobj).\n",
      "\n",
      "* deprecated from version: 3.0\n",
      "* Will raise <class 'nibabel.deprecator.ExpiredDeprecationError'> as of version: 5.0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap_v  156\n",
      "a  0.00641025641025641\n"
     ]
    }
   ],
   "source": [
    "# if sth went wrong can run it here again for single patient\n",
    "path = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/KORA2452879'\n",
    "listFiles = os.listdir(path)\n",
    "\n",
    "    \n",
    "sequence = 'opp'\n",
    "opp_files = [f for f in listFiles if sequence in f and  '_applied_in_bias_corrected_rescaled_original_resampled' in f ]\n",
    "print(opp_files)\n",
    "merge_images(opp_files, path,sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: rescale intensities for second N4 correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_intensities(img_files, data_dir,sequence):\n",
    "    images = []\n",
    "    # load files\n",
    "    for file in img_files:\n",
    "        if \"nii.gz\" in file:\n",
    "            img = nibabel.load(os.path.join(data_dir, file))\n",
    "            print('filename: ', file)\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            filename, file_extension = os.path.splitext(filename)\n",
    "            \n",
    "            images.append(img)\n",
    "            img_data = img.get_fdata()\n",
    "            min_value = np.min(img_data)\n",
    "            max_value = np.max(img_data)\n",
    "            print('min value: ', min_value )\n",
    "            print('max value: ', max_value)\n",
    "            \n",
    "            if min_value < 0 and abs(min_value) >= 10:\n",
    "                print('Negative values detected!!')                \n",
    "                img_data = img_data + abs(min_value) +10\n",
    "\n",
    "            else:\n",
    "                img_data = img_data + 10\n",
    "            min_value = np.min(img_data)\n",
    "            max_value = np.max(img_data)\n",
    "            print('new min value: ', min_value )\n",
    "            print('new max value: ', max_value)\n",
    "            \n",
    "            new_img_nii = nibabel.Nifti1Image(img_data, img.affine, img.header)\n",
    "            new_file_path = os.path.join(data_dir,filename + '_rescaled.nii.gz')\n",
    "            nibabel.save(new_img_nii, new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/'\n",
    "\n",
    "listFolders =  os.listdir(data_dir)\n",
    "for folder in listFolders:\n",
    "    print(folder)\n",
    "    path = data_dir + folder\n",
    "    listFiles = os.listdir(path)\n",
    "    sequence = 'in'\n",
    "    in_files = [f for f in listFiles if sequence in f and 'corrected_comb_sigm' in f and 'rescaled' not in f ]\n",
    "    print(in_files)\n",
    "    rescale_intensities(in_files, path,sequence)\n",
    "    \n",
    "    sequence = 'opp'\n",
    "    opp_files = [f for f in listFiles if sequence in f and 'corrected_comb_sigm' in f and 'rescaled' not in f ]\n",
    "    print(opp_files)\n",
    "    rescale_intensities(opp_files, path,sequence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_corrected_comb_sigm.nii.gz']\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_corrected_comb_sigm.nii.gz\n",
      "min value:  -9.355963706970215\n",
      "max value:  889.0\n",
      "new min value:  0.6440362930297852\n",
      "new max value:  899.0\n"
     ]
    }
   ],
   "source": [
    "path = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/KORA2452879'\n",
    "listFiles = os.listdir(path)\n",
    "\n",
    "    \n",
    "sequence = 'opp'\n",
    "opp_files = [f for f in listFiles if sequence in f and 'corrected_comb_sigm' in f and 'rescaled' not in f ]\n",
    "print(opp_files)\n",
    "rescale_intensities(opp_files, path,sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: run N4 correction script on in comb files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: apply bias field of in scans on opp scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bias_fields(img_files, bias_fields, data_dir,sequence):\n",
    "    images = []\n",
    "    bias_f = []\n",
    "    filenames = []\n",
    "    # load files\n",
    "    for file in img_files:\n",
    "        if \"nii.gz\" in file:\n",
    "            img = nibabel.load(os.path.join(data_dir, file))\n",
    "            print('filename: ', file)\n",
    "            filename, file_extension = os.path.splitext(file)\n",
    "            filename, file_extension = os.path.splitext(filename)\n",
    "            \n",
    "            images.append(img)\n",
    "            filenames.append(filename)\n",
    "    for file in bias_fields:\n",
    "        if \"nii.gz\" in file:\n",
    "            img = nibabel.load(os.path.join(data_dir, file))\n",
    "            print('filename: ', file)            \n",
    "            bias_f.append(img)\n",
    "\n",
    "    images_sorted, filenames_sorted = zip(*sorted(zip(images,filenames), key=lambda im: im[0].header['qoffset_z'], reverse=True))\n",
    "    bias_f = sorted(bias_f, key=lambda im: im.header['qoffset_z'], reverse=True)\n",
    "    \n",
    "    im_0 = images_sorted[0]\n",
    "    \n",
    "    bias_0 = bias_f[0]\n",
    "    \n",
    "    # manually apply bias field to image:\n",
    "    im_0_data = im_0.get_fdata()\n",
    "    print('min ', np.min(im_0_data))\n",
    "    print('max ', np.max(im_0_data))\n",
    "    bias_0_data = bias_0.get_fdata()\n",
    "    print('min ', np.min(bias_0_data))\n",
    "    print('max ', np.max(bias_0_data))\n",
    "    \n",
    "    corrected_0 = im_0_data / bias_0_data\n",
    "    print('min ', np.min(corrected_0))\n",
    "    print('max ', np.max(corrected_0))\n",
    "\n",
    "    new_img_nii = nibabel.Nifti1Image(corrected_0, im_0.affine, im_0.header)\n",
    "    new_file_path = os.path.join(data_dir,filenames_sorted[0] + '_applied_in_bias_corrected.nii.gz')\n",
    "    nibabel.save(new_img_nii, new_file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/'\n",
    "\n",
    "listFolders =  os.listdir(data_dir)\n",
    "for folder in listFolders:\n",
    "    print(folder)\n",
    "    path = data_dir + folder\n",
    "    listFiles = os.listdir(path)\n",
    "    # sequence for bias fields is 'in'\n",
    "    sequence = 'in'\n",
    "    bias_files = [f for f in listFiles if sequence in f and '_comb_sigm_rescaled_bias_field' in f ]\n",
    "    print(bias_files)\n",
    "    # want to apply in bias fields on opp scans, so load opp scans here:\n",
    "    sequence = 'opp'\n",
    "    opp_files = [f for f in listFiles if sequence in f and '_comb_sigm_rescaled.nii.gz' in f ]\n",
    "    print(opp_files)\n",
    "    apply_bias_fields(opp_files, bias_files, path,sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t1_vibe_dixon_cor_caipi6_bh_288_iso_in_corrected_comb_sigm_rescaled_bias_field.nii.gz']\n",
      "['t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_corrected_comb_sigm_rescaled.nii.gz']\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_opp_corrected_comb_sigm_rescaled.nii.gz\n",
      "filename:  t1_vibe_dixon_cor_caipi6_bh_288_iso_in_corrected_comb_sigm_rescaled_bias_field.nii.gz\n",
      "min  0.6440362930297852\n",
      "max  899.0\n",
      "min  92.43206787109375\n",
      "max  340.2630615234375\n",
      "min  0.006357685659736475\n",
      "max  5.4364844628675115\n"
     ]
    }
   ],
   "source": [
    "path = '/home/anne/whole_body_segmentation/All_KORA_original_data/All/KORA2452879'\n",
    "listFiles = os.listdir(path)\n",
    "\n",
    "    \n",
    "# sequence for bias fields is 'in'\n",
    "sequence = 'in'\n",
    "bias_files = [f for f in listFiles if sequence in f and '_comb_sigm_rescaled_bias_field' in f ]\n",
    "print(bias_files)\n",
    "# want to apply in bias fields on opp scans, so load opp scans here:\n",
    "sequence = 'opp'\n",
    "opp_files = [f for f in listFiles if sequence in f and '_comb_sigm_rescaled.nii.gz' in f ]\n",
    "print(opp_files)\n",
    "apply_bias_fields(opp_files, bias_files, path,sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
